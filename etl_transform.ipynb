{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e72b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (11868, 6)\n",
      "Incremental dataset shape: (1000, 6)\n",
      "Columns after renaming: Index(['Year', 'Cause_Code', 'Cause_Name', 'State', 'Deaths',\n",
      "       'Age_Adjusted_Rate'],\n",
      "      dtype='object')\n",
      "'transformed' folder already exists at: C:\\Users\\USER\\OneDrive\\Desktop\\ET_EXAM_GIFT_662\\transformed\n",
      "\n",
      "[Cleaning] Remove duplicates\n",
      "Full before: (11868, 6)\n",
      "Full after: (10868, 6)\n",
      "Incremental before: (1000, 6)\n",
      "Incremental after: (1000, 6)\n",
      "\n",
      "[Cleaning] Handle missing values\n",
      "Full missing before:\n",
      " Year                 0\n",
      "Cause_Code           0\n",
      "Cause_Name           0\n",
      "State                0\n",
      "Deaths               0\n",
      "Age_Adjusted_Rate    0\n",
      "dtype: int64\n",
      "Full missing after:\n",
      " Year                 0\n",
      "Cause_Code           0\n",
      "Cause_Name           0\n",
      "State                0\n",
      "Deaths               0\n",
      "Age_Adjusted_Rate    0\n",
      "dtype: int64\n",
      "Incremental missing before:\n",
      " Year                 0\n",
      "Cause_Code           0\n",
      "Cause_Name           0\n",
      "State                0\n",
      "Deaths               0\n",
      "Age_Adjusted_Rate    0\n",
      "dtype: int64\n",
      "Incremental missing after:\n",
      " Year                 0\n",
      "Cause_Code           0\n",
      "Cause_Name           0\n",
      "State                0\n",
      "Deaths               0\n",
      "Age_Adjusted_Rate    0\n",
      "dtype: int64\n",
      "\n",
      "[Standardization] Capitalize State\n",
      "Before:\n",
      " 0    United States\n",
      "1          Alabama\n",
      "2           Alaska\n",
      "3          Arizona\n",
      "4         Arkansas\n",
      "Name: State, dtype: object\n",
      "After:\n",
      " 0    United States\n",
      "1          Alabama\n",
      "2           Alaska\n",
      "3          Arizona\n",
      "4         Arkansas\n",
      "Name: State, dtype: object\n",
      "\n",
      "[Enrichment] Add Deaths_Rate_Scaled\n",
      "   Deaths  Deaths_Rate_Scaled\n",
      "0  169936             169.936\n",
      "1    2703               2.703\n",
      "2     436               0.436\n",
      "3    4184               4.184\n",
      "4    1625               1.625\n",
      "\n",
      "[Categorization] Create Rate_Category\n",
      "   Age_Adjusted_Rate Rate_Category\n",
      "0               49.4           Low\n",
      "1               53.8        Medium\n",
      "2               63.7        Medium\n",
      "3               56.2        Medium\n",
      "4               51.8        Medium\n",
      "\n",
      "[Filtering] Keep relevant columns\n",
      "Columns after filtering: Index(['Year', 'Cause_Code', 'Cause_Name', 'State', 'Deaths',\n",
      "       'Age_Adjusted_Rate', 'Rate_Category', 'Deaths_Rate_Scaled'],\n",
      "      dtype='object')\n",
      "\n",
      "Transformed datasets saved in '/transformed/' folder\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Transform Phase — etl_transform.ipynb\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load datasets from data/\n",
    "# -----------------------------\n",
    "raw_path = r'C:\\Users\\USER\\OneDrive\\Desktop\\ET_EXAM_GIFT_662\\data\\validated_data.csv'\n",
    "inc_path = r'C:\\Users\\USER\\OneDrive\\Desktop\\ET_EXAM_GIFT_662\\data\\incremental_data.csv'\n",
    "\n",
    "full_df = pd.read_csv(raw_path)\n",
    "inc_df = pd.read_csv(inc_path)\n",
    "\n",
    "print(\"Full dataset shape:\", full_df.shape)\n",
    "print(\"Incremental dataset shape:\", inc_df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 1b. Rename columns for easier access\n",
    "# -----------------------------\n",
    "rename_cols = {\n",
    "    '113 Cause Name': 'Cause_Code',\n",
    "    'Cause Name': 'Cause_Name',\n",
    "    'Age-adjusted Death Rate': 'Age_Adjusted_Rate'\n",
    "}\n",
    "\n",
    "full_df.rename(columns=rename_cols, inplace=True)\n",
    "inc_df.rename(columns=rename_cols, inplace=True)\n",
    "print(\"Columns after renaming:\", full_df.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Prepare 'transformed/' folder\n",
    "# -----------------------------\n",
    "transformed_folder = r'C:\\Users\\USER\\OneDrive\\Desktop\\ET_EXAM_GIFT_662\\transformed'\n",
    "if not os.path.exists(transformed_folder):\n",
    "    os.makedirs(transformed_folder)\n",
    "    print(f\"'transformed' folder created at: {transformed_folder}\")\n",
    "else:\n",
    "    print(f\"'transformed' folder already exists at: {transformed_folder}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Apply Transformations\n",
    "# -----------------------------\n",
    "\n",
    "# 3.1 Cleaning — Remove duplicates\n",
    "print(\"\\n[Cleaning] Remove duplicates\")\n",
    "print(\"Full before:\", full_df.shape)\n",
    "full_df = full_df.drop_duplicates()\n",
    "print(\"Full after:\", full_df.shape)\n",
    "\n",
    "print(\"Incremental before:\", inc_df.shape)\n",
    "inc_df = inc_df.drop_duplicates()\n",
    "print(\"Incremental after:\", inc_df.shape)\n",
    "\n",
    "# 3.2 Cleaning — Handle missing values\n",
    "print(\"\\n[Cleaning] Handle missing values\")\n",
    "print(\"Full missing before:\\n\", full_df.isnull().sum())\n",
    "full_df['Deaths'] = full_df['Deaths'].fillna(full_df['Deaths'].median())\n",
    "full_df['Age_Adjusted_Rate'] = full_df['Age_Adjusted_Rate'].fillna(full_df['Age_Adjusted_Rate'].median())\n",
    "print(\"Full missing after:\\n\", full_df.isnull().sum())\n",
    "\n",
    "print(\"Incremental missing before:\\n\", inc_df.isnull().sum())\n",
    "inc_df['Deaths'] = inc_df['Deaths'].fillna(inc_df['Deaths'].median())\n",
    "inc_df['Age_Adjusted_Rate'] = inc_df['Age_Adjusted_Rate'].fillna(inc_df['Age_Adjusted_Rate'].median())\n",
    "print(\"Incremental missing after:\\n\", inc_df.isnull().sum())\n",
    "\n",
    "# 3.3 Standardization — Capitalize State\n",
    "print(\"\\n[Standardization] Capitalize State\")\n",
    "print(\"Before:\\n\", full_df['State'].head())\n",
    "full_df['State'] = full_df['State'].str.title()\n",
    "inc_df['State'] = inc_df['State'].str.title()\n",
    "print(\"After:\\n\", full_df['State'].head())\n",
    "\n",
    "# 3.4 Enrichment — Add Deaths_Rate_Scaled\n",
    "print(\"\\n[Enrichment] Add Deaths_Rate_Scaled\")\n",
    "full_df['Deaths_Rate_Scaled'] = full_df['Deaths'] / 1000\n",
    "inc_df['Deaths_Rate_Scaled'] = inc_df['Deaths'] / 1000\n",
    "print(full_df[['Deaths', 'Deaths_Rate_Scaled']].head())\n",
    "\n",
    "# 3.5 Categorization — Create Rate_Category\n",
    "print(\"\\n[Categorization] Create Rate_Category\")\n",
    "bins = [0, 50, 100, 200, 1000]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "full_df['Rate_Category'] = pd.cut(full_df['Age_Adjusted_Rate'], bins=bins, labels=labels)\n",
    "inc_df['Rate_Category'] = pd.cut(inc_df['Age_Adjusted_Rate'], bins=bins, labels=labels)\n",
    "print(full_df[['Age_Adjusted_Rate', 'Rate_Category']].head())\n",
    "\n",
    "# 3.6 Filtering — Keep only relevant columns\n",
    "print(\"\\n[Filtering] Keep relevant columns\")\n",
    "cols = ['Year', 'Cause_Code', 'Cause_Name', 'State', 'Deaths', \n",
    "        'Age_Adjusted_Rate', 'Rate_Category', 'Deaths_Rate_Scaled']\n",
    "full_df = full_df[cols]\n",
    "inc_df = inc_df[cols]\n",
    "print(\"Columns after filtering:\", full_df.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Save transformed datasets\n",
    "# -----------------------------\n",
    "full_df.to_csv(os.path.join(transformed_folder, 'transformed_full.csv'), index=False)\n",
    "inc_df.to_csv(os.path.join(transformed_folder, 'transformed_incremental.csv'), index=False)\n",
    "print(\"\\nTransformed datasets saved in '/transformed/' folder\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
